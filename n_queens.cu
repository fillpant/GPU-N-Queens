#include "deffinitions.cuh"
#include "cuda_runtime.h"
#include <string.h>
#include <stdio.h>
#include <stdlib.h>
#include "n_queens.cuh"
#include "diagonals.cuh"
#include <stdbool.h>
#include <math.h>
#include <assert.h>
#include "nq_utils.cuh"


/**
* Generate states by advancing a copy of the given master state. The master state is not modified and may be in any condition,
* however it must be ensured that multiple calls to this function which are later merged, should be started at distinct points.
* On error, the errno is set and NULL is returned.
*
* @param master The master state to advance to produce new states. Access to this state is assumed to be alias-free.
* @param lock_at_row The row up to which queens will be placed.
* @param max_number_of_states The absolute maximum number of states to generate.
*        If this number is reached during generation, generation is stopped and NULL is returned. If this param is zero, no limit is imposed.
* @param generated_cnt Pointer to a uint64 where the count of generated states is written.
* @return A buffer of nq_state_t generated by successive advancement of the master state.
*        The returned buffer may be larger than generated_cnt states.
*/
__host__ nq_state_t* gen_states_rowlock(const nq_state_t* const __restrict__ master_state, const unsigned lock_at_row, const uint64_t max_number_of_states, uint64_t* __restrict__ const generated_cnt) {
	nq_state_t master;
	memcpy(&master, master_state, sizeof(nq_state_t));
	const unsigned locked_rows_top = master.curr_row;

	nq_state_t* approx_states = (nq_state_t*)malloc(sizeof(nq_state_t) * STATE_GENERATION_POOL_COUNT);
	uint64_t buf_len = STATE_GENERATION_POOL_COUNT;

	if (!approx_states) {
		errno = ENOMEM;
		return NULL;
	}
	const uint64_t limit = max_number_of_states ? max_number_of_states : UINT64_MAX;
	uint64_t cnt;
	for (cnt = 0; cnt < limit; ++cnt) {
		bool advanced;
		do {
			advanced = locked_advance_nq_state(&master, locked_rows_top, lock_at_row - 1);
		} while (advanced && (!NQ_FREE_COLS_AT(&master, master.curr_row + 1) || master.queen_at_index[master.curr_row] == UNSET_QUEEN_INDEX));
		if (advanced) {
			memcpy(&approx_states[cnt], &master, sizeof(nq_state_t));
			++approx_states[cnt].curr_row;
			if (buf_len - 1 == cnt) {
				buf_len += STATE_GENERATION_POOL_COUNT;
				nq_state_t* reallocd_approx_states = (nq_state_t*)realloc(approx_states, sizeof(nq_state_t) * buf_len);
				if (!reallocd_approx_states) {
					errno = ENOMEM;
					free(approx_states);
					return NULL;
				} else {
					approx_states = reallocd_approx_states;
				}
			}
		} else {
			break;
		}
	}
	//States generated are either exactly as many as the max value, or the loop exited as it hit the limit.
	if (cnt == UINT64_MAX) {
		errno = EOVERFLOW;
		free(approx_states);
		return NULL;
	}
	if (max_number_of_states == cnt) {
		errno = ERANGE;
		free(approx_states);
		return NULL;
	}
	*generated_cnt = cnt;
	return approx_states;
}

#ifdef ENABLE_THREADED_STATE_GENERATION
#include <pthread.h>

typedef struct {
	unsigned first_queen_idx, lock_at_row, error_code;
	uint64_t absolute_max_count, result_len;
	nq_state_t* result_ptr;
} internal_state_gen_thread_data_t;

typedef struct {
	void* src, *dest;
	size_t data_size;
} internal_memcpy_thread_data_t;

static void* internal_memcpy_thread(void* dataptr) {
	internal_memcpy_thread_data_t* dat = (internal_memcpy_thread_data_t*) dataptr;
	memcpy(dat->dest, dat->src, dat->data_size);
	pthread_exit(NULL);
	return NULL;
}	

/**
* Represents a thread which, generates n many states based on the parameters given.
* @param datptr Pointer to an internal_state_gen_thread_data_t struct.
*/
static void* internal_gen_states_rowlocked_thread(void* datptr) {
	internal_state_gen_thread_data_t* dat = (internal_state_gen_thread_data_t*)datptr;
	dat->error_code = 0;
	nq_state_t master = init_nq_state();
	place_queen_at(&master, 0, dat->first_queen_idx);
	++master.curr_row;

	dat->result_ptr = gen_states_rowlock(&master, dat->lock_at_row, dat->absolute_max_count, &dat->result_len);
	dat->error_code = errno;
	pthread_exit(NULL);
	return NULL;
}



static nq_state_t* gen_states_threaded(const uint64_t how_many, uint64_t* const __restrict__ returned_count, unsigned* __restrict__ locked_row_end) {
	FAIL_IF(!returned_count);
	const uint64_t absolute_max_states = (uint64_t)(how_many * (1 + STATE_GENERATION_LIMIT_PLAY_FACTOR));
	unsigned int lock_at_row = (unsigned int)(log((double)how_many) / log(N));
	lock_at_row = lock_at_row >= N ? N - 1 : lock_at_row;
	FAIL_IF(!lock_at_row);

	typedef struct { uint64_t total_len; internal_state_gen_thread_data_t thread_data[N]; unsigned locked_at; } buf_t;

	buf_t tmp, actual; tmp = actual = { 0, {}, 0 };

	internal_state_gen_thread_data_t threads[N];
	pthread_t thread_ids[N];
	memset(&actual, 0, sizeof(buf_t));

	do {
		printf("Lock at row %u... ", lock_at_row);
		fflush(stdout);
		//Free last 'actual' result
		for (unsigned i = 0; i < N; ++i)
			if (actual.thread_data[i].result_ptr) {
				free(actual.thread_data[i].result_ptr);
				actual.thread_data[i].result_ptr = 0;
			}
		actual = tmp;
		memset(&tmp, 0, sizeof(buf_t));

		// Clear previous thread data and re-configure
		memset(threads, 0, sizeof(internal_state_gen_thread_data_t));
		for (unsigned i = 0; i < N; ++i) {
			threads[i].absolute_max_count = absolute_max_states;
			threads[i].first_queen_idx = i;
			threads[i].lock_at_row = lock_at_row;
			pthread_create(&thread_ids[i], NULL, internal_gen_states_rowlocked_thread, &threads[i]);
		}

		// Wait for each thread to finish
		for (unsigned i = 0; i < N; ++i)
			pthread_join(thread_ids[i], NULL);

		// Collect data from each thread.
		for (unsigned i = 0; i < N; ++i) {
			if (threads[i].error_code) {
				fprintf(stderr, "Thread %u failed with error code %u.\n", i, threads[i].error_code);
				goto loopend;
			}
			tmp.total_len += threads[i].result_len;
			tmp.thread_data[i] = threads[i];
			tmp.locked_at = lock_at_row;
		}
		printf("%" PRIu64" states generated\n", tmp.total_len);
		lock_at_row++;
	} while (
#if STATE_GENERATION_DOWNSLOPE_BOUNDED == 1
		tmp.total_len >= actual.total_len &&
#endif
		lock_at_row <= N && tmp.total_len <= absolute_max_states
		);
loopend:

	//If first is null, actual wasn't initialized by the above loop
	FAIL_IF(!actual.thread_data[0].result_ptr);

	// Cleanup tmp 
	for (unsigned i = 0; i < N; ++i)
		if (tmp.thread_data[i].result_ptr)
			free(tmp.thread_data[i].result_ptr);

	nq_state_t* states = (nq_state_t*)malloc(sizeof(nq_state_t) * actual.total_len);

	uint64_t offset = 0;
	for (unsigned i = 0; i < N; ++i) {
		memcpy(states + offset, actual.thread_data[i].result_ptr, sizeof(nq_state_t) * actual.thread_data[i].result_len);
		offset += actual.thread_data[i].result_len;
		free(actual.thread_data[i].result_ptr);
	}
	FAIL_IF(offset != actual.total_len)
		* returned_count = actual.total_len;
	*locked_row_end = actual.locked_at;
	return states;
}

#else 
static nq_state_t* internal_gen_states_rowlocked(const unsigned int lock_at_row, uint64_t* const returned_count, const uint64_t absolute_max_count) {
	nq_state_t master = init_nq_state();

	/*nq_state_t* approx_states;
	uint64_t buf_len = 0;
	if (existing_states) {
		approx_states = existing_states;
		buf_len = existing_cnt;
	} else {
		approx_states = (nq_state_t*)malloc(sizeof(nq_state_t) * STATE_GENERATION_POOL_COUNT);
		buf_len = STATE_GENERATION_POOL_COUNT;
	}
	if (!approx_states)
		return NULL;


	uint64_t cnt;
	for (cnt = 0; cnt < absolute_max_count; ++cnt) {
		bool advanced;
		do {
			advanced = locked_advance_nq_state(&master, 0, lock_at_row - 1);
		} while (advanced && //While we have made an advancement and that advancement is either:
			(!NQ_FREE_COLS_AT(&master, master.curr_row + 1) || //unsolvable further or
				master.queen_at_index[master.curr_row] == UNSET_QUEEN_INDEX //or not fully explored (i.e. unset queen at last locked row)
				));

		if (advanced) {
			memcpy(&approx_states[cnt], &master, sizeof(nq_state_t));
			approx_states[cnt].curr_row++; //We need this to be pointing at the first empty row (which is not the current value
			//Resize buffer if needed
			if (buf_len - 1 == cnt) {
				//Linear incremental resize. Whilst this means more calls to realloc, it gives finer controll over the buffer allowing
				//us to use full memory if needs be without tremendous overallocation
				buf_len += STATE_GENERATION_POOL_COUNT;
				nq_state_t* reallocd_approx_states = (nq_state_t*)realloc(approx_states, sizeof(nq_state_t) * buf_len);
				if (!reallocd_approx_states) {
					free(approx_states);
					return NULL;
				} else {
					approx_states = reallocd_approx_states;
				}
			}
		} else {
			break;
		}
	}
	if (absolute_max_count == cnt) {
		free(approx_states);
		return NULL;
	}*/

	return gen_states_rowlock(&master, lock_at_row, absolute_max_count, returned_count);
}

static nq_state_t* gen_states(const unsigned int how_many, uint64_t* const __restrict__ returned_count, unsigned* __restrict__ locked_row_end) {
	FAIL_IF(!returned_count);
	const uint64_t absolute_max_states = (how_many * ((uint64_t)(1 + STATE_GENERATION_LIMIT_PLAY_FACTOR)));
	unsigned int lock_at_row = (unsigned int)(log(how_many) / log(N));
	lock_at_row = lock_at_row >= N ? N - 1 : lock_at_row;
	FAIL_IF(!lock_at_row);

	typedef struct { uint64_t len; nq_state_t* ptr; unsigned locked_at; } buf_t;

	buf_t tmp, actual;
	tmp = actual = { 0, NULL , 0 };

	do {
		FAIL_IF(tmp.ptr && tmp.ptr == actual.ptr);
		if (actual.ptr)
			free(actual.ptr);
		actual = tmp;
		tmp.locked_at = lock_at_row;
		printf("Lock at row %u...", lock_at_row);
		fflush(stdout);
		tmp.ptr = internal_gen_states_rowlocked(lock_at_row, &tmp.len, 0);
		printf(" %" PRIu64" states generated.\n", tmp.len);
		if (!tmp.ptr) {
			printf("Failed to allocate memory or allocation surrpaces maximum state count when locking at row %u\n", lock_at_row);
			break;
		}
		lock_at_row++;
	} while (
#if STATE_GENERATION_DOWNSLOPE_BOUNDED == 1
		tmp.len >= actual.len &&
#endif
		lock_at_row <= N && tmp.len < absolute_max_states);

	FAIL_IF(!actual.ptr);
	if (tmp.ptr)
		free(tmp.ptr);

	*returned_count = actual.len;
	*locked_row_end = actual.locked_at;
	return actual.ptr;
}


#endif


__host__ nq_state_t* nq_generate_states(const uint64_t how_many, uint64_t* const __restrict__ returned_count, unsigned* __restrict__ locked_row_end) {
	FAIL_IF(!returned_count);
	return
#ifdef ENABLE_THREADED_STATE_GENERATION
		gen_states_threaded
#else
		gen_states
#endif
		(how_many, returned_count, locked_row_end);
}
















/**
* Generate as many states as possible by locking at a specific depth (row) of a board. Generation is happening
* accross N many threads.
* In case of failure during generation, errno is set appropriately, and NULL is returned. The value of returned_count
* is then arbitrary.
*
* @param row_lock Row upon which to lock for state generation.
* @param returned_count Pass back pointer for the length of the generated state buffer. This location
*		may contain arbitrary data in case of failure.
* @return a pointer to an nq_state_t buffer of at least returned_count many elements, or NULL in case of failure.
*/
static nq_state_t* gen_states_threaded_rowlock(const unsigned row_lock, uint64_t* const __restrict__ returned_count) {
	FAIL_IF(!returned_count);
	*returned_count = 0;
	internal_state_gen_thread_data_t threads[N] = {};
	pthread_t thread_ids[N] = {};

	printf("Lock at row %u... ", row_lock);
	fflush(stdout);

	for (unsigned i = 0; i < N; ++i) {
		threads[i].first_queen_idx = i;
		threads[i].lock_at_row = row_lock;
		pthread_create(&thread_ids[i], NULL, internal_gen_states_rowlocked_thread, &threads[i]);
	}

	// Wait for each thread to finish
	for (unsigned i = 0; i < N; ++i)
		pthread_join(thread_ids[i], NULL);


	nq_state_t* states = NULL;
	uint64_t offset = 0;
	// Collect data from each thread.
	for (unsigned i = 0; i < N; ++i) {
		if (threads[i].error_code) {
			fprintf(stderr, "Thread %u failed with error code %u.\n", i, threads[i].error_code);
			goto gen_failed;
		}
		*returned_count += threads[i].result_len;
	}
	printf("%" PRIu64" states generated\nAllocating concatenation buffer...", *returned_count);
	states = (nq_state_t*)malloc(sizeof(nq_state_t) * *returned_count);

	internal_memcpy_thread_data_t memcpyDat[N];
	for (unsigned i = 0; i < N; ++i) {
		memcpyDat[i].dest = states + offset;
		memcpyDat[i].src = threads[i].result_ptr;
		memcpyDat[i].data_size = sizeof(nq_state_t)* threads[i].result_len;
		pthread_create(&thread_ids[i], NULL, internal_memcpy_thread, &memcpyDat[i]);
		//memcpy(states + offset, threads[i].result_ptr, sizeof(nq_state_t) * threads[i].result_len);
		offset += threads[i].result_len;
		//free(threads[i].result_ptr);
	}
	// Wait for each thread to finish memcpying
	for (unsigned i = 0; i < N; ++i) {
		pthread_join(thread_ids[i], NULL);
		//Free each buffer after the thread is done using it.
		free(memcpyDat[i].src);
	}

	FAIL_IF(offset != *returned_count);
	goto done;
gen_failed:
	// cleanup.
	for (unsigned i = 0; i < N; ++i)
		if (threads[i].result_ptr)
			free(threads[i].result_ptr);
done:
	return states;
}


__host__ nq_state_t* nq_generate_states_rowlock(const unsigned row_lock, uint64_t* const __restrict__ returned_count) {
	FAIL_IF(!returned_count || row_lock == 0);

#ifdef ENABLE_THREADED_STATE_GENERATION
	return gen_states_threaded_rowlock(row_lock, returned_count);
#else
	nq_state_t master = init_nq_state();
	return gen_states_rowlock(&master, row_lock, 0, returned_count);
#endif

}



// Perform the same function as the GPU in advancing a state except the end point is 'fixed' and may not be the end of the board.
__host__ bool locked_advance_nq_state(nq_state_t* __restrict__ s, const unsigned locked_top_cols, const unsigned int lock) {
	while (s->curr_row >= (signed char)locked_top_cols) {
		const unsigned char queen_index = s->queen_at_index[s->curr_row];
		bitset32_t free_cols = NQ_FREE_COLS(s);

		if (queen_index != UNSET_QUEEN_INDEX) {
			free_cols &= (N_MASK << (queen_index + 1));
			remove_queen_at(s, s->curr_row, queen_index);
		}

		if (free_cols == 0)
			--(s->curr_row);
		else {
			bit_index_t	FFS(free_cols, place_at);
			place_at--;
			place_queen_at(s, s->curr_row, (unsigned char)place_at);
			if (s->curr_row < (int)lock)
				s->curr_row++;
			return true;
		}
	}
	return false;
}

// NOTE: Assumes s is not an empty state!! There must be at least one queen on it.
__host__ bool host_doublesweep_light_nq_state(nq_state_t* __restrict__ s) {
	bool changed = false;
	do {
		const unsigned char queen_index = s->queen_at_index[s->curr_row];
		if (queen_index != UNSET_QUEEN_INDEX)
			break;

		bitset32_t free_cols = NQ_FREE_COLS(s);
		const int POPCNT(free_cols, popcnt);

		//Exactly one place we can use. 
		if (popcnt == 1) {
			bit_index_t FFS(free_cols, place_at);
			place_queen_at(s, s->curr_row, (unsigned char)place_at - 1);
			if (s->curr_row < N - 1)
				s->curr_row++;
			changed = true;
		} else
			break;
	} while (1);
	return changed;
}

__host__ nq_state_t init_nq_state(void) {
	nq_state_t state;
	clear_nq_state(&state);
	return state;
}

__host__ void clear_nq_state(nq_state_t* state) {
	state->queens_in_columns = 0;
	state->diagonals = dad_init_blank();
	state->curr_row = 0;
	memset(state->queen_at_index, UNSET_QUEEN_INDEX, sizeof(state->queen_at_index));

}
