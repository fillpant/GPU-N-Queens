#include "deffinitions.cuh"
#include "cuda_runtime.h"
#include <string.h>
#include <stdio.h>
#include <stdlib.h>
#include "n_queens.cuh"
#include "diagonals.cuh"
#include <stdbool.h>
#include <math.h>
#include <assert.h>
#include "nq_utils.cuh"
#include "nq_mem_utilities.cuh"

/**
* Generate states by advancing a copy of the given master state. The master state is not modified and may be in any condition,
* however it must be ensured that multiple calls to this function which are later merged, should be started at distinct points.
* On error, the errno is set and NULL is returned.
*
* @param master The master state to advance to produce new states. Access to this state is assumed to be alias-free.
* @param lock_at_row The row up to which queens will be placed.
* @param max_number_of_states The absolute maximum number of states to generate.
*        If this number is reached during generation, generation is stopped and NULL is returned. If this param is zero, no limit is imposed.
* @param generated_cnt Pointer to a uint64 where the count of generated states is written.
* @return A buffer of nq_state_t generated by successive advancement of the master state.
*        The returned buffer may be larger than generated_cnt states.
*/
__host__ nq_mem_handle_t* gen_states_rowlock(const nq_state_t* const __restrict__ master_state, const unsigned lock_at_row, const uint64_t max_number_of_states, uint64_t* __restrict__ const generated_cnt) {
	nq_state_t master;
	memcpy(&master, master_state, sizeof(nq_state_t));
	const unsigned locked_rows_top = master.curr_row;

	//nq_state_t* approx_states = (nq_state_t*)malloc(sizeof(nq_state_t) * STATE_GENERATION_POOL_COUNT
	nq_mem_handle_t* alloc = (nq_mem_handle_t*)malloc(sizeof(nq_mem_handle_t));
	nq_mem_init(alloc);
	nq_state_t* approx_states = (nq_state_t*)nq_mem_alloc(alloc, sizeof(nq_state_t) * STATE_GENERATION_POOL_COUNT);

	uint64_t buf_len = STATE_GENERATION_POOL_COUNT;

	if (!approx_states) {
		errno = ENOMEM;
		return NULL;
	}
	const uint64_t limit = max_number_of_states ? max_number_of_states : UINT64_MAX;
	uint64_t cnt;
	for (cnt = 0; cnt < limit; ++cnt) {
		bool advanced;
		do {
			advanced = locked_advance_nq_state(&master, locked_rows_top, lock_at_row - 1);
		} while (advanced && (!NQ_FREE_COLS_AT(&master, master.curr_row + 1) || master.queen_at_index[master.curr_row] == UNSET_QUEEN_INDEX));
		if (advanced) {
			memcpy(&approx_states[cnt], &master, sizeof(nq_state_t));
			++approx_states[cnt].curr_row;
			if (buf_len - 1 == cnt) {
				buf_len += STATE_GENERATION_POOL_COUNT;
				nq_state_t* reallocd_approx_states = (nq_state_t*)nq_mem_realloc(alloc, sizeof(nq_state_t) * buf_len);
				if (!reallocd_approx_states) {
					errno = ENOMEM;
					nq_mem_free(alloc);
					return NULL;
				} else {
					approx_states = reallocd_approx_states;
				}
			}
		} else {
			break;
		}
	}
	//States generated are either exactly as many as the max value, or the loop exited as it hit the limit.
	if (cnt == UINT64_MAX) {
		errno = EOVERFLOW;
		nq_mem_free(alloc);
		return NULL;
	}
	if (max_number_of_states == cnt) {
		errno = ERANGE;
		nq_mem_free(alloc);
		return NULL;
	}
	*generated_cnt = cnt;
	return alloc;
}

#ifdef ENABLE_THREADED_STATE_GENERATION
#include <pthread.h>

typedef struct {
	unsigned first_queen_idx, lock_at_row, error_code;
	uint64_t absolute_max_count, result_len;
	nq_mem_handle_t mem;
	//nq_state_t* result_ptr;
} internal_state_gen_thread_data_t;

typedef struct {
	void* src, * dest;
	size_t data_size;
} internal_memcpy_thread_data_t;

static void* internal_memcpy_thread(void* dataptr) {
	internal_memcpy_thread_data_t* dat = (internal_memcpy_thread_data_t*)dataptr;
	memcpy(dat->dest, dat->src, dat->data_size);
	pthread_exit(NULL);
	return NULL;
}

/**
* Represents a thread which, generates n many states based on the parameters given.
* @param datptr Pointer to an internal_state_gen_thread_data_t struct.
*/
static void* internal_gen_states_rowlocked_thread(void* datptr) {
	internal_state_gen_thread_data_t* dat = (internal_state_gen_thread_data_t*)datptr;
	dat->error_code = 0;
	nq_state_t master = init_nq_state();
	place_queen_at(&master, 0, dat->first_queen_idx);
	++master.curr_row;

	nq_mem_handle_t* m = gen_states_rowlock(&master, dat->lock_at_row, dat->absolute_max_count, &dat->result_len);
	memcpy(&dat->mem, m, sizeof(nq_mem_handle_t));
	free(m);
	dat->error_code = errno;
	pthread_exit(NULL);
	return NULL;
}



static nq_mem_handle_t* gen_states_threaded(const uint64_t how_many, uint64_t* const __restrict__ returned_count, unsigned* __restrict__ locked_row_end) {
	FAIL_IF(!returned_count);
#ifdef ENABLE_STATIC_HALF_SEARCHSPACE_REFLECTION_ELIMINATION
#define GEN_STATES_TCNT CEILING(N,2)
#else
#define GEN_STATES_TCNT N
#endif
	const uint64_t absolute_max_states = (uint64_t)(how_many * (1 + STATE_GENERATION_LIMIT_PLAY_FACTOR));
	//TODO Untested logic. Log base GEN_STATES_TCNT or GEN_STATES_TCNT+1?
	unsigned int lock_at_row = (unsigned int)(log((double)how_many) / log(GEN_STATES_TCNT+1));
	lock_at_row = lock_at_row >= N ? N - 1 : lock_at_row;
	FAIL_IF(!lock_at_row);

	typedef struct { uint64_t total_len; internal_state_gen_thread_data_t thread_data[N]; unsigned locked_at; } buf_t;

	buf_t tmp, actual; tmp = actual = { 0, {}, 0 };

	internal_state_gen_thread_data_t threads[GEN_STATES_TCNT];
	pthread_t thread_ids[GEN_STATES_TCNT];
	memset(&actual, 0, sizeof(buf_t));

	do {
		printf("Lock at row %u... ", lock_at_row);
		fflush(stdout);
		//Free last 'actual' result
		for (unsigned i = 0; i < GEN_STATES_TCNT; ++i)
			if (actual.thread_data[i].mem.mem_ptr) {
				nq_mem_free(&actual.thread_data[i].mem);
				actual.thread_data[i].mem.mem_ptr = 0;
			}
		actual = tmp;
		memset(&tmp, 0, sizeof(buf_t));

		// Clear previous thread data and re-configure
		memset(threads, 0, sizeof(internal_state_gen_thread_data_t));
		for (unsigned i = 0; i < GEN_STATES_TCNT; ++i) {
			threads[i].absolute_max_count = absolute_max_states;
			threads[i].first_queen_idx = i;
			threads[i].lock_at_row = lock_at_row;
			nq_mem_init(&threads[i].mem);
			pthread_create(&thread_ids[i], NULL, internal_gen_states_rowlocked_thread, &threads[i]);
		}

		// Wait for each thread to finish
		for (unsigned i = 0; i < GEN_STATES_TCNT; ++i)
			pthread_join(thread_ids[i], NULL);

		// Collect data from each thread.
		for (unsigned i = 0; i < GEN_STATES_TCNT; ++i) {
			if (threads[i].error_code) {
				fprintf(stderr, "Thread %u failed with error code %u.\n", i, threads[i].error_code);
				goto loopend;
			}
			tmp.total_len += threads[i].result_len;
			tmp.thread_data[i] = threads[i];
			tmp.locked_at = lock_at_row;
		}
		printf("%" PRIu64" states generated\n", tmp.total_len);
		lock_at_row++;
	} while (
#if STATE_GENERATION_DOWNSLOPE_BOUNDED == 1
		tmp.total_len >= actual.total_len &&
#endif
		lock_at_row <= N && tmp.total_len <= absolute_max_states
		);
loopend:

	//If first is null, actual wasn't initialized by the above loop
	FAIL_IF(!actual.thread_data[0].mem.mem_ptr);

	// Cleanup tmp 
	for (unsigned i = 0; i < GEN_STATES_TCNT; ++i)
		if (tmp.thread_data[i].mem.mem_ptr)
			nq_mem_free(&tmp.thread_data[i].mem);

	nq_mem_handle_t* unified = (nq_mem_handle_t*)malloc(sizeof(nq_mem_handle_t));
	nq_mem_init(unified);

	nq_state_t* states = (nq_state_t*)nq_mem_alloc(unified, sizeof(nq_state_t) * actual.total_len);

	uint64_t offset = 0;
	for (unsigned i = 0; i < GEN_STATES_TCNT; ++i) {
		memcpy(states + offset, actual.thread_data[i].mem.mem_ptr, sizeof(nq_state_t) * actual.thread_data[i].result_len);
		offset += actual.thread_data[i].result_len;
		nq_mem_free(&actual.thread_data[i].mem);
	}
	FAIL_IF(offset != actual.total_len);
	*returned_count = actual.total_len;
	*locked_row_end = actual.locked_at;
	return unified;
#undef GEN_STATES_TCNT
}




/**
* Generate as many states as possible by locking at a specific depth (row) of a board. Generation is happening
* accross N many threads.
* In case of failure during generation, errno is set appropriately, and NULL is returned. The value of returned_count
* is then arbitrary.
*
* @param row_lock Row upon which to lock for state generation.
* @param returned_count Pass back pointer for the length of the generated state buffer. This location
*		may contain arbitrary data in case of failure.
* @return a pointer to an nq_state_t buffer of at least returned_count many elements, or NULL in case of failure.
*/
static nq_mem_handle_t* gen_states_threaded_rowlock(const unsigned row_lock, uint64_t* const __restrict__ returned_count) {
	FAIL_IF(!returned_count);
	*returned_count = 0;
	internal_state_gen_thread_data_t threads[N] = {};
	pthread_t thread_ids[N] = {};

	printf("Lock at row %u... ", row_lock);
	fflush(stdout);

	for (unsigned i = 0; i < N; ++i) {
		threads[i].first_queen_idx = i;
		threads[i].lock_at_row = row_lock;
		nq_mem_init(&threads[i].mem);
		pthread_create(&thread_ids[i], NULL, internal_gen_states_rowlocked_thread, &threads[i]);
	}

	// Wait for each thread to finish
	for (unsigned i = 0; i < N; ++i)
		pthread_join(thread_ids[i], NULL);


	nq_state_t* states = NULL;
	uint64_t offset = 0;
	nq_mem_handle_t* unified = NULL;
	// Collect data from each thread.
	for (unsigned i = 0; i < N; ++i) {
		if (threads[i].error_code) {
			fprintf(stderr, "Thread %u failed with error code %u.\n", i, threads[i].error_code);
			goto gen_failed;
		}
		*returned_count += threads[i].result_len;
	}
	printf("%" PRIu64" states generated\nAllocating concatenation buffer...", *returned_count);
	unified = (nq_mem_handle_t*)malloc(sizeof(nq_mem_handle_t));
	nq_mem_init(unified);
	states = (nq_state_t*)nq_mem_alloc(unified, sizeof(nq_state_t) * *returned_count);

	internal_memcpy_thread_data_t memcpyDat[N];
	for (unsigned i = 0; i < N; ++i) {
		memcpyDat[i].dest = states + offset;
		memcpyDat[i].src = threads[i].mem.mem_ptr;
		memcpyDat[i].data_size = sizeof(nq_state_t) * threads[i].result_len;
		pthread_create(&thread_ids[i], NULL, internal_memcpy_thread, &memcpyDat[i]);
		//memcpy(states + offset, threads[i].result_ptr, sizeof(nq_state_t) * threads[i].result_len);
		offset += threads[i].result_len;
		//free(threads[i].result_ptr);
	}
	// Wait for each thread to finish memcpying
	for (unsigned i = 0; i < N; ++i) {
		pthread_join(thread_ids[i], NULL);
		//Free each buffer after the thread is done using it.
		nq_mem_free(&threads[i].mem);
		//free(memcpyDat[i].src);
	}

	FAIL_IF(offset != *returned_count);
	goto done;
gen_failed:
	// cleanup.
	for (unsigned i = 0; i < N; ++i)
		if (threads[i].mem.mem_ptr)
			nq_mem_free(&threads[i].mem);
done:
	return unified;
}


#else 
static nq_mem_handle_t* internal_gen_states_rowlocked(const unsigned int lock_at_row, uint64_t* const returned_count, const uint64_t absolute_max_count) {
	nq_state_t master = init_nq_state();
//NOTE: if reflection elimination is enabled, it is assumed that THE LEFT HALF of the board will be populated.
//As such, we can't simply place a queen on position N/2-1 and let gen_states_rowlock give us all states from that position on because
//although the state count is correct, queens are on the RIGHT half and weighting in kernels doesn't work properly.
#ifdef ENABLE_STATIC_HALF_SEARCHSPACE_REFLECTION_ELIMINATION
	uint64_t total_len, tmp_len;
	master.curr_row=1;
	place_queen_at(&master, 0, 0);
	nq_mem_handle_t* buf = gen_states_rowlock(&master, lock_at_row, absolute_max_count, &total_len);

	for (int i = 1; i < CEILING(N, 2); ++i) {
		remove_queen_at(&master, 0, i-1);
		place_queen_at(&master, 0, i);
		nq_mem_handle_t* tmp_res = gen_states_rowlock(&master, lock_at_row, absolute_max_count, &tmp_len);
		nq_mem_realloc(buf, (total_len + tmp_len) * sizeof(nq_state_t));
		memcpy(((nq_state_t*)buf->mem_ptr)+total_len, tmp_res->mem_ptr, sizeof(nq_state_t) * tmp_len);
		nq_mem_free(tmp_res);
		total_len += tmp_len;
	}
	*returned_count = total_len;
	return buf;
#else
	return gen_states_rowlock(&master, lock_at_row, absolute_max_count, returned_count);
#endif
}

//Generate states by search.
static nq_mem_handle_t* gen_states(const unsigned int how_many, uint64_t* const __restrict__ returned_count, unsigned* __restrict__ locked_row_end) {
	FAIL_IF(!returned_count);
	const uint64_t absolute_max_states = (how_many * ((uint64_t)(1 + STATE_GENERATION_LIMIT_PLAY_FACTOR)));
	unsigned int lock_at_row = (unsigned int)(log(how_many) / log(N));
	lock_at_row = lock_at_row >= N ? N - 1 : lock_at_row;
	FAIL_IF(!lock_at_row);

	typedef struct { uint64_t len; nq_mem_handle_t* mem; unsigned locked_at; } buf_t;

	buf_t tmp, actual;
	tmp = actual = { 0, NULL , 0 };

	do {
		FAIL_IF(tmp.mem && actual.mem && tmp.mem->mem_ptr == actual.mem->mem_ptr);
		if (actual.mem)
			nq_mem_free(actual.mem);
		actual = tmp;
		tmp.locked_at = lock_at_row;
		printf("Lock at row %u...", lock_at_row);
		fflush(stdout);

		nq_mem_handle_t* mh = internal_gen_states_rowlocked(lock_at_row, &tmp.len, 0);
		tmp.mem = mh;

		printf(" %" PRIu64" states generated.\n", tmp.len);
		if (!tmp.mem) {
			printf("Failed to allocate memory or allocation surrpaces maximum state count when locking at row %u\n", lock_at_row);
			break;
		}
		lock_at_row++;
	} while (
#if STATE_GENERATION_DOWNSLOPE_BOUNDED == 1
		tmp.len >= actual.len &&
#endif
		lock_at_row <= N && tmp.len < absolute_max_states);

	FAIL_IF(!actual.mem);
	if (tmp.mem && tmp.mem->mem_ptr)
		nq_mem_free(tmp.mem);

	*returned_count = actual.len;
	*locked_row_end = actual.locked_at;
	return actual.mem;
}
#endif


//////////////////////////////////////////////////////////////////////////////////

//Entry point function to count-oriented state generation.
__host__ nq_mem_handle_t* nq_generate_states(const uint64_t how_many, uint64_t* const __restrict__ returned_count, unsigned* __restrict__ locked_row_end) {
	FAIL_IF(!returned_count);
	return
#ifdef ENABLE_THREADED_STATE_GENERATION
		gen_states_threaded
#else
		gen_states
#endif
		(how_many, returned_count, locked_row_end);
}

//Entry point function to row-oriented state generation.
__host__ nq_mem_handle_t* nq_generate_states_rowlock(const unsigned row_lock, uint64_t* const __restrict__ returned_count) {
	FAIL_IF(!returned_count || row_lock == 0);

#ifdef ENABLE_THREADED_STATE_GENERATION
	return gen_states_threaded_rowlock(row_lock, returned_count);
#else
	nq_state_t master = init_nq_state();
	return gen_states_rowlock(&master, row_lock, 0, returned_count);
#endif


}

// Perform the same function as the GPU in advancing a state except the end point is 'fixed' and may not be the end of the board.
__host__ bool locked_advance_nq_state(nq_state_t* __restrict__ s, const unsigned locked_top_cols, const unsigned int lock) {
	while (s->curr_row >= (signed char)locked_top_cols) {
		const unsigned char queen_index = s->queen_at_index[s->curr_row];
		bitset32_t free_cols = NQ_FREE_COLS(s);

		if (queen_index != UNSET_QUEEN_INDEX) {
			free_cols &= (N_MASK << (queen_index + 1));
			remove_queen_at(s, s->curr_row, queen_index);
		}

		if (free_cols == 0)
			--(s->curr_row);
		else {
			bit_index_t	FFS(free_cols, place_at);
			place_at--;
			place_queen_at(s, s->curr_row, (unsigned char)place_at);
			if (s->curr_row < (int)lock)
				s->curr_row++;
			return true;
		}
	}
	return false;
}

// NOTE: Assumes s is not an empty state!! There must be at least one queen on it.
__host__ bool host_doublesweep_light_nq_state(nq_state_t* __restrict__ s) {
	bool changed = false;
	do {
		const unsigned char queen_index = s->queen_at_index[s->curr_row];
		if (queen_index != UNSET_QUEEN_INDEX)
			break;

		bitset32_t free_cols = NQ_FREE_COLS(s);
		const int POPCNT(free_cols, popcnt);

		//Exactly one place we can use. 
		if (popcnt == 1) {
			bit_index_t FFS(free_cols, place_at);
			place_queen_at(s, s->curr_row, (unsigned char)place_at - 1);
			if (s->curr_row < N - 1)
				s->curr_row++;
			changed = true;
		} else
			break;
	} while (1);
	return changed;
}

__host__ nq_state_t init_nq_state(void) {
	nq_state_t state;
	clear_nq_state(&state);
	return state;
}

__host__ void clear_nq_state(nq_state_t* state) {
	state->queens_in_columns = 0;
	state->diagonals = dad_init_blank();
	state->curr_row = 0;
	memset(state->queen_at_index, UNSET_QUEEN_INDEX, sizeof(state->queen_at_index));

}
